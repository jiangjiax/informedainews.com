---
title: "NIST Launches Open-Source Platform for AI Safety Testing"
description: "NIST Launches Open-Source Platform for AI Safety Testing"

---


:::info

"Informed AI News" is an publications aggregation platform, ensuring you only gain the most valuable information, to eliminate information asymmetry and break through the limits of information cocoons.  [Find out more >>](/)

:::

# NIST Launches Open-Source Platform for AI Safety Testing

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs
	defaultValue="summary"
	values={[
	{label: 'summary', value: 'summary'},
	{label: 'score', value: 'score'},
]}>
<TabItem value="summary">


NIST, the National Institute of Standards and Technology, has launched Dioptra, an open-source tool designed to test the resilience of machine learning models against various attacks. Dioptra features a web-based interface, user authentication, and comprehensive tracking of experiment elements to ensure reproducibility.

The tool is equipped to handle three types of attacks: evasion, poisoning, and oracle. Evasion attacks involve manipulating input data to deceive models. Poisoning attacks tamper with training data, thereby reducing model accuracy. Oracle attacks attempt to reverse-engineer models to gain insights into their datasets or parameters.

Dioptra's modular architecture supports a wide range of experiments, allowing for the combination of different models, datasets, attack methods, and defense strategies. It is accessible to a broad audience, including model developers, users, testers, auditors, and researchers. The platform also supports Python plugins for enhanced functionality and maintains detailed histories of experiments for traceable testing.

In addition, NIST has released three guidance documents. The first document addresses 12 risks associated with generative AI and provides over 200 recommended actions. The second document outlines secure software development practices for generative AI and dual-use foundation models. The third document proposes a plan for global cooperation in the development of AI standards.
</TabItem>
<TabItem value="score">
	| Scores     | Value   | Explanation |
	| -------- | ------- | ------- |
	| Objectivity  | 7    | Comprehensive, balanced reporting on AI safety testing.    |
	| Social Impact | 4     | Influences AI development and security discussions.    |
	| Credibility    | 6    | Solid evidence from authoritative source, NIST.    |
	| Potential    | 5    | High potential to impact AI model testing and security.    |
	| Practicality    | 5    | Extremely practical for AI model testing.    |
	| Entertainment Value    | 2    | Low entertainment value, focused on tech.    |
</TabItem>
</Tabs>

[Full article>>](https://yro.slashdot.org/story/24/08/04/021242/nist-releases-an-open-source-platform-for-ai-safety-testing?utm_source=rss1.0mainlinkanon&utm_medium=feed)
