---
title: "OpenAI DevDay Unveils Realtime API and Vision Fine-Tuning for AI Developers"
description: "OpenAI DevDay Unveils Realtime API and Vision Fine-Tuning for AI Developers"

---


:::info

"Informed AI News" is an publications aggregation platform, ensuring you only gain the most valuable information, to eliminate information asymmetry and break through the limits of information cocoons.  [Find out more >>](/)

:::

# OpenAI DevDay Unveils Realtime API and Vision Fine-Tuning for AI Developers

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs
	defaultValue="summary"
	values={[
	{label: 'summary', value: 'summary'},
	{label: 'score', value: 'score'},
]}>
<TabItem value="summary">


OpenAI's 2024 DevDay unveiled new tools for developers, despite recent executive departures. The highlight: a public beta of the Realtime API, enabling low-latency, AI-generated voice responses in apps. Six distinct voices are available, though third-party options are restricted to avoid copyright issues.

A demo showcased a trip planning app using the Realtime API, featuring verbal interactions with an AI assistant and real-time map annotations. The API can also integrate with calling services like Twilio for tasks such as ordering food, though it lacks direct calling capabilities.

Vision fine-tuning was introduced, allowing developers to use images alongside text to enhance GPT-4o’s visual understanding. OpenAI emphasized that copyrighted or inappropriate images are prohibited.

Prompt caching, similar to Anthropic’s feature, promises to reduce API costs and latency by caching frequently used context. Model distillation lets developers fine-tune smaller AI models using larger ones, offering cost savings and performance improvements.

Despite these advancements, OpenAI didn’t announce new AI models or updates on the GPT Store, which was teased last year. Developers eagerly awaiting OpenAI o1 or the Sora video generation model will need to wait longer.

**Key Terms:**
- **Realtime API:** An interface allowing developers to integrate AI-generated voice responses with low latency into their apps.
- **Vision fine-tuning:** A process enabling AI models to better understand and process visual data.
- **Model distillation:** A technique where a smaller AI model is fine-tuned using the knowledge of a larger model, aiming for better performance at lower costs.
</TabItem>
<TabItem value="score">
	| Scores     | Value   | Explanation |
	| -------- | ------- | ------- |
	| Objectivity  | 6    | Comprehensive reporting with in-depth analysis.    |
	| Social Impact | 4     | Strong social discussion, influencing some public opinion.    |
	| Credibility    | 5    | Solid evidence from authoritative sources.    |
	| Potential    | 5    | Very high potential to trigger larger events.    |
	| Practicality    | 5    | Extremely practical, widely applied in practice.    |
	| Entertainment Value    | 3    | Some entertainment value, attracts a portion of the audience.    |
</TabItem>
</Tabs>

[Full article>>](https://techcrunch.com/2024/10/01/openais-devday-brings-realtime-api-and-other-treats-for-ai-app-developers/)
