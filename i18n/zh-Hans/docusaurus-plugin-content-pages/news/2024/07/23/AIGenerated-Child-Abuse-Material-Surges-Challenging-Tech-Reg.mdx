---
title: "AI-Generated Child Abuse Material Surges, Challenging Tech Regulation"
description: "AI-Generated Child Abuse Material Surges, Challenging Tech Regulation"

---


:::info

"Informed AI News" is an publications aggregation platform, ensuring you only gain the most valuable information, to eliminate information asymmetry and break through the limits of information cocoons.  [Find out more >>](/)

:::

# AI-Generated Child Abuse Material Surges, Challenging Tech Regulation

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

<Tabs
	defaultValue="summary"
	values={[
	{label: 'summary', value: 'summary'},
	{label: 'score', value: 'score'},
]}>
<TabItem value="summary">


Generative AI is fueling a surge in online child sexual abuse materials (CSAM). The UK's Internet Watch Foundation (IWF) reports a 17% increase in AI-altered CSAM since fall 2023. Deepfake content, using real victims' imagery, is rampant. One forum shared 3,512 explicit images and videos in 30 days, mostly of young girls. Offenders share advice and AI models fed by real images.

IWF CEO Susie Hargreaves warns, "Without proper controls, generative AI tools provide a playground for online predators." The technology is advancing rapidly, creating more lifelike synthetic videos. Of 12,000 AI-generated images on a dark web forum, 90% were realistic enough to be assessed as real CSAM.

Apple faces allegations of underreporting CSAM shared via its products. The National Society for the Prevention of Cruelty to Children (NSPCC) claims Apple was implicated in 337 offenses in England and Wales alone between April 2022 and March 2023, while reporting only 267 cases worldwide to the National Center for Missing and Exploited Children (NCMEC).

Google reported over 1.47 million CSAM cases to NCMEC in 2023. Facebook removed 14.4 million pieces of child sexual exploitation content between January and March this year. Despite these efforts, the battle against online child exploitation intensifies with the misuse of generative AI.
</TabItem>
<TabItem value="score">
	| Scores     | Value   | Explanation |
	| -------- | ------- | ------- |
	| Objectivity  | 6    | Comprehensive reporting with in-depth analysis.    |
	| Social Impact | 5     | Significantly influences public opinion on AI misuse.    |
	| Credibility    | 5    | Solid evidence from authoritative sources.    |
	| Potential    | 6    | Inevitably leads to significant changes in tech regulation.    |
	| Practicality    | 4    | Directly applicable to real problems in tech regulation.    |
	| Entertainment Value    | 2    | Contains few entertaining elements.    |
</TabItem>
</Tabs>

[Full article>>](https://sea.mashable.com/tech-industry/33529/online-child-sex-abuse-material-boosted-by-ai-is-outpacing-big-techs-regulation)
